{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "civilian-guinea",
   "metadata": {},
   "source": [
    "# Object Detection Example\n",
    "## onnx model by YOLOv5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surprising-corporation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\user\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\user\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\user\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\user\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\user\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\user\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\user\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\user\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car']\n",
      "Input Name: images\n",
      "Output Name: ['output', '524', '585', '646']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort \n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as trns\n",
    "from PIL import Image\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# Define image transforms\n",
    "transforms = trns.Compose([trns.Resize((640, 640)), trns.ToTensor()])\n",
    "# transforms = trns.Compose([trns.Resize((224, 224)), trns.ToTensor(), trns.Normalize(\n",
    "#     mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "onnxmodel_path='./yolov5m.onnx'\n",
    "image_paths = ['images/Car.jpg',\n",
    "              'images/cat.jpg',\n",
    "              'images/Cruise-ships-1.png',\n",
    "              'images/people1.jpg',\n",
    "               'images/sheep1.jpeg',\n",
    "              'images/horse.jpg']\n",
    "class_def = 'coco.names'\n",
    "\n",
    "# Load MSCOCO classes\n",
    "with open(class_def) as f:\n",
    "    classesname = [line.strip() for line in f.readlines()]\n",
    "print(classesname[:3])\n",
    "# Run the model on the backend\n",
    "session = ort.InferenceSession(onnxmodel_path)\n",
    "# get the name of the first input of the model\n",
    "input_name = session.get_inputs()[0].name  \n",
    "output_name = [tmp.name for tmp in session.get_outputs()]\n",
    "print('Input Name:', input_name)\n",
    "print('Output Name:', output_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-thing",
   "metadata": {},
   "source": [
    "# NMS function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "framed-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh2xyxy(x):\n",
    "    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y\n",
    "\n",
    "def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,\n",
    "                        labels=(), max_det=300):\n",
    "    \"\"\"Runs Non-Maximum Suppression (NMS) on inference results\n",
    "    Returns:\n",
    "         list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n",
    "    \"\"\"\n",
    "    nc = prediction.shape[2] - 5  # number of classes\n",
    "    xc = prediction[..., 4] > conf_thres  # candidates\n",
    "    \n",
    "\n",
    "#     # Checks\n",
    "#     assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'\n",
    "#     assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'\n",
    "\n",
    "    # Settings\n",
    "    min_wh, max_wh = 2, 4096  # (pixels) minimum and maximum box width and height\n",
    "    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
    "    time_limit = 10.0  # seconds to quit after\n",
    "    redundant = True  # require redundant detections\n",
    "    multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "    merge = False  # use merge-NMS\n",
    "\n",
    "    t = time.time()\n",
    "#     output = [torch.zeros((prediction.shape[1], 6), device=prediction.device)] * prediction.shape[0]\n",
    "    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        \n",
    "        # Apply constraints\n",
    "        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "        x = x[xc[xi]]  # confidence\n",
    "\n",
    "        # Cat apriori labels if autolabelling\n",
    "        if labels and len(labels[xi]):\n",
    "            l = labels[xi]\n",
    "            v = torch.zeros((len(l), nc + 5), device=x.device)\n",
    "            v[:, :4] = l[:, 1:5]  # box\n",
    "            v[:, 4] = 1.0  # conf\n",
    "            v[range(len(l)), l[:, 0].long() + 5] = 1.0  # cls\n",
    "            x = torch.cat((x, v), 0)\n",
    "\n",
    "        # If none remain process next image\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Compute conf\n",
    "        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
    "        # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "        box = xywh2xyxy(x[:, :4])\n",
    "        \n",
    "        \n",
    "        # Detections matrix nx6 (xyxy, conf, cls)\n",
    "        if multi_label:\n",
    "            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
    "            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
    "            \n",
    "        else:  # best class only\n",
    "            conf, j = x[:, 5:].max(1, keepdim=True)\n",
    "            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
    "\n",
    "            \n",
    "            \n",
    "        # Filter by class\n",
    "        if classes is not None:\n",
    "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    " \n",
    "            \n",
    "        # Apply finite constraint\n",
    "        # if not torch.isfinite(x).all():\n",
    "        #     x = x[torch.isfinite(x).all(1)]\n",
    "\n",
    "        # Check shape\n",
    "        n = x.shape[0]  # number of boxes\n",
    "        if not n:  # no boxes\n",
    "            continue\n",
    "        elif n > max_nms:  # excess boxes\n",
    "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence\n",
    "        \n",
    "        \n",
    "        # Batched NMS\n",
    "        c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
    "        boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores\n",
    "        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "        if i.shape[0] > max_det:  # limit detections\n",
    "            i = i[:max_det]\n",
    "        if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\n",
    "            # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\n",
    "            iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix\n",
    "            weights = iou * scores[None]  # box weights\n",
    "            x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes\n",
    "            if redundant:\n",
    "                i = i[iou.sum(1) > 1]  # require redundancy\n",
    "        output[xi] = x[i]\n",
    "        if (time.time() - t) > time_limit:\n",
    "            print(f'WARNING: NMS time limit {time_limit}s exceeded')\n",
    "            break  # time limit exceeded\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "english-pastor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "images/Car.jpg\n",
      "Output size:torch.Size([1, 25200, 85])\n",
      "********\n",
      "images/cat.jpg\n",
      "Output size:torch.Size([1, 25200, 85])\n",
      "********\n",
      "images/Cruise-ships-1.png\n",
      "Output size:torch.Size([1, 25200, 85])\n",
      "********\n",
      "images/people1.jpg\n",
      "Output size:torch.Size([1, 25200, 85])\n",
      "********\n",
      "images/sheep1.jpeg\n",
      "Output size:torch.Size([1, 25200, 85])\n",
      "********\n",
      "images/horse.jpg\n",
      "Output size:torch.Size([1, 25200, 85])\n"
     ]
    }
   ],
   "source": [
    "conf=0.15  # confidence threshold\n",
    "iou=0.6 # NMS IOU threshold\n",
    "classes = 80\n",
    "max_det = 100\n",
    "cuda = 0\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "agnostic_nms=False\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    print('********')\n",
    "    print(image_path)\n",
    "    # Read image and run prepro\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    ori_w,ori_h=image.size\n",
    "    \n",
    "    image_tensor = transforms(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    image_np = image_tensor.numpy()\n",
    "\n",
    "    outputs = session.run([session.get_outputs()[0].name], {session.get_inputs()[0].name: image_np})[0]\n",
    "    outputs = torch.tensor(outputs)\n",
    "    print(\"Output size:{}\".format(outputs.shape))\n",
    "    pred = non_max_suppression(outputs, conf_thres=conf, iou_thres=iou,  agnostic=agnostic_nms, max_det=max_det)\n",
    "   \n",
    "\n",
    "#     print(pred[0].shape)#  list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n",
    "#     print(pred[0])#  list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n",
    "    \n",
    "    \n",
    "    img_cv = cv2.cvtColor(np.asarray(image), cv2.COLOR_RGB2BGR)\n",
    "    for box in pred[0]:\n",
    "        x_min = int(box[0]/640*ori_w)\n",
    "        y_min = int(box[1]/640*ori_h)\n",
    "        x_max = int(box[2]/640*ori_w)\n",
    "        y_max = int(box[3]/640*ori_h)\n",
    "        conf = box[4]\n",
    "        cls = int(box[5])\n",
    "        cv2.rectangle(img_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "        cv2.putText(img_cv, '{},s={:.2f}'.format(classesname[cls],conf), (x_min, y_min+10), cv2.FONT_HERSHEY_TRIPLEX,1, (255, 125, 0), 1, cv2.LINE_AA)\n",
    "    image_path\n",
    "    cv2.imwrite('result_{}.jpg'.format(i), img_cv)\n",
    "#     break\n",
    "    \n",
    "\n",
    "#     outputs = session.run(output_name, {input_name: image_np}) \n",
    "#     print(outputs[0].shape)\n",
    "#     print(outputs[1].shape)\n",
    "#     print(outputs[2].shape)\n",
    "#     print(outputs[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-recommendation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
